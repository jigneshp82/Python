{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@35ca9c40\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@35ca9c40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.Row\n",
    "import java.util.Properties\n",
    "\n",
    "val spark = SparkSession.builder().appName(\"Online Retail Analysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class OnlineRetalDS\n",
       "OnlineRetailSchema = StructType(StructField(InvoiceNo,StringType,true), StructField(stockCode,IntegerType,true), StructField(description,StringType,true), StructField(quantity,IntegerType,true), StructField(invoiceDate,StringType,true), StructField(unitPrice,DoubleType,true), StructField(customerID,StringType,true), StructField(country,StringType,true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(InvoiceNo,StringType,true), StructField(stockCode,IntegerType,true), StructField(description,StringType,true), StructField(quantity,IntegerType,true), StructField(invoiceDate,StringType,true), StructField(unitPrice,DoubleType,true), StructField(customerID,StringType,true), StructField(country,StringType,true))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType, DoubleType,DateType};\n",
    "\n",
    "\n",
    "\n",
    "case class OnlineRetalDS (InvoiceNo: String, stockCode: Int, description: String, quantity: Int, \n",
    "                   invoiceDate: String, unitPrice: Double,customerID: String, country: String)\n",
    "\n",
    "val OnlineRetailSchema = StructType( \n",
    "             List(\n",
    "            StructField(\"InvoiceNo\", StringType, true),\n",
    "            StructField(\"stockCode\", IntegerType, true),\n",
    "            StructField(\"description\", StringType, true),\n",
    "            StructField(\"quantity\", IntegerType, true),\n",
    "            StructField(\"invoiceDate\", StringType, true),\n",
    "            StructField(\"unitPrice\", DoubleType, true),\n",
    "            StructField(\"customerID\", StringType, true),\n",
    "            StructField(\"country\", StringType, true)\n",
    "            ))\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|stockCode|         description|quantity|   invoiceDate|unitPrice|customerID|       country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|     null|     null|                null|    null|          null|     null|      null|          null|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|     null|     null|                null|    null|          null|     null|      null|          null|\n",
      "|     null|     null|                null|    null|          null|     null|      null|          null|\n",
      "|     null|     null|                null|    null|          null|     null|      null|          null|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/2010 8:26|     7.65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/2010 8:26|     4.25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|12/1/2010 8:34|     1.69|     13047|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|12/1/2010 8:34|     3.75|     13047|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|12/1/2010 8:34|     1.65|     13047|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|12/1/2010 8:34|     4.25|     13047|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|12/1/2010 8:34|     4.95|     13047|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|12/1/2010 8:34|     9.95|     13047|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|12/1/2010 8:34|     7.95|     13047|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OnlineRetailDF = [InvoiceNo: string, stockCode: int ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, stockCode: int ... 6 more fields]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val OnlineRetailDF = spark.read.format(\"csv\")\n",
    ".option(\"header\",\"true\")\n",
    ".option(\"timestampFormat\",\"dd/MM/yy HH:mm\")\n",
    ".schema(OnlineRetailSchema)\n",
    ".load(\"/home/jignesh/Downloads/OnlineRetailNew.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OnlineRetailDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OnlineRetailDF1 = [InvoiceNo: string, stockCode: int ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, stockCode: int ... 6 more fields]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val OnlineRetailDF1 = OnlineRetailDF.filter('InvoiceNo =!= \"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+-------------------+\n",
      "|InvoiceNo|stockCode|         description|quantity|   invoiceDate|unitPrice|customerID|       country|                 ts|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+-------------------+\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|2010-01-12 08:26:00|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/2010 8:26|     7.65|     17850|United Kingdom|2010-01-12 08:26:00|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/2010 8:26|     4.25|     17850|United Kingdom|2010-01-12 08:26:00|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|2010-01-12 08:28:00|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|2010-01-12 08:28:00|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|12/1/2010 8:34|     1.69|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|12/1/2010 8:34|     3.75|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|12/1/2010 8:34|     1.65|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|12/1/2010 8:34|     4.25|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|12/1/2010 8:34|     4.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|12/1/2010 8:34|     9.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|12/1/2010 8:34|     7.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536367|    48187| DOORMAT NEW ENGLAND|       4|12/1/2010 8:34|     7.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536368|    22960|JAM MAKING SET WI...|       6|12/1/2010 8:34|     4.25|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536368|    22913|RED COAT RACK PAR...|       3|12/1/2010 8:34|     4.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "|   536368|    22912|YELLOW COAT RACK ...|       3|12/1/2010 8:34|     4.95|     13047|United Kingdom|2010-01-12 08:34:00|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OnlineRetailTS = [InvoiceNo: string, stockCode: int ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, stockCode: int ... 7 more fields]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val OnlineRetailTS = OnlineRetailDF1.withColumn(\"ts\",\n",
    "                                                unix_timestamp($\"InvoiceDate\",\"dd/MM/yy HH:mm\").cast(\"timestamp\"))\n",
    "\n",
    "OnlineRetailTS.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OnlineRetailTS.createOrReplaceTempView(\"RetailTable\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r3DF = [InvoiceNo: string, stockCode: int ... 7 more fields]\n",
       "r4DF = [InvoiceNo: string, stockCode: int ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, stockCode: int ... 7 more fields]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r3DF= spark.sql(\"select * from RetailTable where ts <'2011-12-01'\")\n",
    "val r4DF= spark.sql(\"select * from RetailTable where ts >'2011-12-01'\")\n",
    "\n",
    "//spark.sql(\"select customerID, count(*) from RetailTable group by customerID order by count(*) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+\n",
      "|InvoiceNo|stockCode|         description|quantity|unitPrice|customerID|       country|        invoiceDate|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+\n",
      "|   540848|    90204|PAIR OF ENAMEL BU...|       1|     3.39|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21043|APRON MODERN VINT...|       1|     4.21|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21520|BOOZE & WOMEN GRE...|       2|     0.43|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21707|FOLDING UMBRELLA ...|       1|     3.36|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21884|CAKES AND BOWS GI...|       7|     0.43|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    22144|CHRISTMAS CRAFT L...|       1|     4.21|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    22219|LOVEBIRD HANGING ...|       3|     1.66|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    22385|JUMBO BAG SPACEBO...|       2|     4.21|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    22641|SET OF 4 NAPKIN C...|       1|     1.66|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    22804|CANDLEHOLDER PINK...|       1|     5.91|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21916|SET 12 RETRO WHIT...|       1|     0.85|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21918|SET 12 KIDS COLOU...|       1|     0.85|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21931|JUMBO STORAGE BAG...|       1|     4.21|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21934|  SKULL SHOULDER BAG|       3|     1.66|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21935|  SUKI  SHOULDER BAG|       2|     1.66|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21943|CAKES AND RABBITS...|       1|     1.66|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21947|SET OF 6 HEART CH...|       3|     1.28|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21948|SET OF 6 CAKE CHO...|       1|     1.28|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21949|SET OF 6 STRAWBER...|       2|     1.28|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "|   540848|    21975|PACK OF 60 DINOSA...|       1|     1.28|      null|United Kingdom|2011-12-01 09:26:00|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "selectdata = [InvoiceNo: string, stockCode: int ... 6 more fields]\n",
       "writedata = [InvoiceNo: string, stockCode: int ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, stockCode: int ... 6 more fields]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val selectdata = r4DF.select(\"InvoiceNo\",\"stockCode\",\"description\",\"quantity\",\"unitPrice\"\n",
    "                             ,\"customerID\",\"country\",\"ts\")\n",
    "val writedata = selectdata.withColumnRenamed(\"ts\",\"invoiceDate\")\n",
    "writedata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dbURL = jdbc:mysql://localhost:3306/TestDB?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC\n",
       "prop = {user=jignesh, password=Data1234}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{user=jignesh, password=Data1234}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dbURL = \"jdbc:mysql://localhost:3306/TestDB?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC\"\n",
    "val prop = new Properties()\n",
    "prop.setProperty(\"user\",\"jignesh\")\n",
    "prop.setProperty(\"password\",\"Data1234\")\n",
    "writedata.write.mode(\"append\").jdbc(dbURL,\"transactions\",prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.SparkException\n",
       "Message: Job aborted.\n",
       "StackTrace:   at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:196)\n",
       "  at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n",
       "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n",
       "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n",
       "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n",
       "  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n",
       "  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n",
       "  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)\n",
       "  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)\n",
       "  ... 72 elided\n",
       "Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 41.0 failed 1 times, most recent failure: Lost task 1.0 in stage 41.0 (TID 463, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:254)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:168)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /users/OnllineRetail/_temporary/0/_temporary/attempt_20190809222820_0041_m_000001_0/part-00001-8b26296a-865b-4e1c-b20b-c9606b4bae9d-c000.json could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.\n",
       "\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2121)\n",
       "\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:295)\n",
       "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2702)\n",
       "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)\n",
       "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)\n",
       "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
       "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n",
       "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n",
       "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)\n",
       "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)\n",
       "\tat java.security.AccessController.doPrivileged(Native Method)\n",
       "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
       "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)\n",
       "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)\n",
       "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
       "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
       "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
       "\tat com.sun.proxy.$Proxy28.addBlock(Unknown Source)\n",
       "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
       "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
       "\tat com.sun.proxy.$Proxy29.addBlock(Unknown Source)\n",
       "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
       "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
       "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
       "Driver stacktrace:\n",
       "  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n",
       "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n",
       "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n",
       "  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
       "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
       "  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n",
       "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
       "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
       "  at scala.Option.foreach(Option.scala:257)\n",
       "  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n",
       "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n",
       "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n",
       "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n",
       "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
       "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n",
       "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n",
       "  at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:166)\n",
       "  ... 93 more\n",
       "Caused by: org.apache.spark.SparkException: Task failed while writing rows.\n",
       "  at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:254)\n",
       "  at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n",
       "  at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:168)\n",
       "  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
       "  at org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
       "  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n",
       "  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
       "  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n",
       "  ... 3 more\n",
       "Caused by: org.apache.hadoop.ipc.RemoteException: File /users/OnllineRetail/_temporary/0/_temporary/attempt_20190809222820_0041_m_000001_0/part-00001-8b26296a-865b-4e1c-b20b-c9606b4bae9d-c000.json could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.\n",
       "\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2121)\n",
       "\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:295)\n",
       "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2702)\n",
       "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)\n",
       "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)\n",
       "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
       "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n",
       "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n",
       "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)\n",
       "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)\n",
       "\tat java.security.AccessController.doPrivileged(Native Method)\n",
       "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
       "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)\n",
       "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)\n",
       "  at org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
       "  at org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
       "  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
       "  at com.sun.proxy.$Proxy28.addBlock(Unknown Source)\n",
       "  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
       "  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "  at java.lang.reflect.Method.invoke(Method.java:498)\n",
       "  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
       "  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
       "  at com.sun.proxy.$Proxy29.addBlock(Unknown Source)\n",
       "  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
       "  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writedata.select(\"*\").write.format(\"json\").save(\"hdfs://localhost:9000/users/OnllineRetail\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
